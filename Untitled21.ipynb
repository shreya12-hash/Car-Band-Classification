{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "round-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,Lambda,Dense,Flatten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "economic-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "greek-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "placed-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "higher-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "needed-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "meaningful-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img \n",
    "#imageDataGenerator help us to do data argumentation that is help us to generate new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "integral-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wrapped-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "documentary-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hybrid-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "amino-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-size all the images to this\n",
    "IMAGE_SIZE=[224,224]\n",
    "train_path='C:/Users/Biswas/Desktop/Train'\n",
    "valid_path='C:/Users/Biswas/Desktop/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "local-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Resnet 50 as shown below and add preprocessing layer to the front of ResNet 50\n",
    "resnet=ResNet50(input_shape=IMAGE_SIZE+[3],weights=\"imagenet\",include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-prophet",
   "metadata": {},
   "source": [
    "1.Why I have added '[3]' with image sze?\n",
    "   \n",
    "   As we provide RGB image data to ResNet model to classifiy images and '[3]=> [Red,Green,Blue]'.That's why we have         added 3 channel with gray scale image of size [224,224]\n",
    "    \n",
    "2.Why I have used weights as 'imagenet' to train ResNet model?\n",
    "     \n",
    "     Imagenet is a data set of images of 1000 categories and ResNet model was trained using this dataset and was able to      correctly classify all 1000 categories.That's why we have reused the same weights that is 'imagenet' to utilize the model efficiently in our case.      \n",
    "\n",
    "3.Why have we assigned include_top=False?\n",
    "    \n",
    "    Because in ResNet we have 1000 categories to images to classify but we have only 3 categories of images so we don't need to include 1st and last layer and at top most layer we need to put my own dataset that's why we assign include_top=False. \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "outer-discharge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "appointed-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't train existing weights \n",
    "for layer in resnet.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-cocktail",
   "metadata": {},
   "source": [
    "Whatever weights are initialized in ResNet 50 I have just reused those I don't retrain those(That's why I have assigned layer.trainable=False) but I have to retrain the last layer because  in last layer the no. of nodes will be based on no. of categories of our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "greek-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful for getting no. of output classes\n",
    "folders=glob('C:/Users/Biswas/Desktop/Train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "continent-antarctica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Biswas/Desktop/Train\\\\audi',\n",
       " 'C:/Users/Biswas/Desktop/Train\\\\lamborghini',\n",
       " 'C:/Users/Biswas/Desktop/Train\\\\mercedes']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "opening-hospital",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-messenger",
   "metadata": {},
   "source": [
    "This length indicates that no. of categories of our output that are present in our neural network that is LSTM neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "positive-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#our layers we can add more if you want\n",
    "x=Flatten()(resnet.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-amateur",
   "metadata": {},
   "source": [
    "Flatening is required before connecting to a fully connected layer.Converting some no.of features 2D into 1D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "statewide-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=Dense(len(folders),activation='softmax')(x)\n",
    "\n",
    "#create a model object\n",
    "model=Model(inputs=resnet.input,outputs=prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-macro",
   "metadata": {},
   "source": [
    "Prediction is a dense layer with 3 nodes and activation function is 'softmax'\n",
    "\n",
    "Softmax is just like a sigmoid function which will be able to classify multiple categories.\n",
    "\n",
    "Dense layer is a simple ANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pointed-barbados",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100352)       0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            301059      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,888,771\n",
      "Trainable params: 301,059\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "associate-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tell the model what cost and optimization methid to use\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "unlike-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the ImageDataGenerator to import images from the data sets.\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-greenhouse",
   "metadata": {},
   "source": [
    "Reading images from the folder when we read all images from the folder we have to use a technique called dataaugmenattion to get more new inages from the given images.\n",
    "\n",
    "Data Augmentation is a technique of creating more images from a given iamges by chaning properties i.e. by adding lot of variation in images\n",
    "\n",
    "Data Augmentation can be done by using ImageDataGenerator which reads the images from the folders then it applies some kind of argmentations like scaling,zooming,fliping,vertical fliping, \n",
    "\n",
    "Data Augemntation is required so that from any views the object will be recognized.\n",
    "\n",
    "Before using data augmentation we have to scale each pixel value of the images so that each pixel value is between 0 to 1 \n",
    "\n",
    "In test data we should not use data augmentation, we use only rescaling..  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "auburn-gibraltar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#Make sure we have to provide same target size as initialized for the image size\n",
    "training_set=train_datagen.flow_from_directory('C:/Users/Biswas/Desktop/Train',\n",
    "                                             target_size=(224,224),\n",
    "                                             batch_size=32,\n",
    "                                             class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-airport",
   "metadata": {},
   "source": [
    "We have to keep same target size as our input size and we have assigned class_mode as 'categorixal' becaue we have more than 2 classes.\n",
    "\n",
    "Using 'flow_from_directory' function data augmentation is applied to each images of training data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "effective-canon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set=test_datagen.flow_from_directory('C:/Users/Biswas/Desktop/Test',\n",
    "                                             target_size=(224,224),\n",
    "                                             batch_size=32,\n",
    "                                             class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "urban-blame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-63ac9454ab97>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 7.3726 - accuracy: 0.3594 - val_loss: 8.3789 - val_accuracy: 0.1552\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 5.6531 - accuracy: 0.3438 - val_loss: 3.9398 - val_accuracy: 0.5172\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 6.3725 - accuracy: 0.4219 - val_loss: 4.4342 - val_accuracy: 0.3276\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 5.8824 - accuracy: 0.4531 - val_loss: 2.5833 - val_accuracy: 0.5690\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 3.0140 - accuracy: 0.4531 - val_loss: 3.4466 - val_accuracy: 0.1552\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 3.1795 - accuracy: 0.4219 - val_loss: 5.0811 - val_accuracy: 0.1552\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 2.9485 - accuracy: 0.4062 - val_loss: 3.6204 - val_accuracy: 0.3276\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 7s 4s/step - loss: 1.8386 - accuracy: 0.4688 - val_loss: 1.9812 - val_accuracy: 0.5345\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 7s 4s/step - loss: 2.0624 - accuracy: 0.5000 - val_loss: 2.0468 - val_accuracy: 0.5345\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 7s 4s/step - loss: 1.7600 - accuracy: 0.5312 - val_loss: 2.0506 - val_accuracy: 0.2241\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 1.1591 - accuracy: 0.5156 - val_loss: 2.4588 - val_accuracy: 0.3276\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 9s 4s/step - loss: 1.4352 - accuracy: 0.4531 - val_loss: 1.2544 - val_accuracy: 0.5862\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 9s 5s/step - loss: 1.0848 - accuracy: 0.5781 - val_loss: 1.3076 - val_accuracy: 0.5862\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 9s 5s/step - loss: 1.0833 - accuracy: 0.6250 - val_loss: 1.5921 - val_accuracy: 0.3621\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.8169 - accuracy: 0.6562 - val_loss: 1.6349 - val_accuracy: 0.4310\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.9779 - accuracy: 0.5938 - val_loss: 1.1403 - val_accuracy: 0.6379\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.7850 - accuracy: 0.6875 - val_loss: 1.1722 - val_accuracy: 0.6034\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.8125 - accuracy: 0.6719 - val_loss: 1.3128 - val_accuracy: 0.4310\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.6187 - accuracy: 0.6875 - val_loss: 1.6075 - val_accuracy: 0.4138\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.7265 - accuracy: 0.6875 - val_loss: 1.0471 - val_accuracy: 0.6379\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.7000 - accuracy: 0.7188 - val_loss: 0.9731 - val_accuracy: 0.6724\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.6299 - accuracy: 0.6719 - val_loss: 1.4441 - val_accuracy: 0.4483\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.5945 - accuracy: 0.7656 - val_loss: 1.1025 - val_accuracy: 0.6207\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.4825 - accuracy: 0.8281 - val_loss: 0.9835 - val_accuracy: 0.7069\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.4457 - accuracy: 0.8125 - val_loss: 0.8787 - val_accuracy: 0.6379\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.3809 - accuracy: 0.8750 - val_loss: 1.1393 - val_accuracy: 0.5517\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.3163 - accuracy: 0.9219 - val_loss: 0.8808 - val_accuracy: 0.6724\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.2929 - accuracy: 0.9062 - val_loss: 0.8731 - val_accuracy: 0.7241\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.3906 - accuracy: 0.8125 - val_loss: 0.9185 - val_accuracy: 0.6552\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.3331 - accuracy: 0.9062 - val_loss: 0.9497 - val_accuracy: 0.6207\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2923 - accuracy: 0.8906 - val_loss: 0.8608 - val_accuracy: 0.7241\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.3631 - accuracy: 0.8750 - val_loss: 0.8856 - val_accuracy: 0.7414\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.2765 - accuracy: 0.8906 - val_loss: 1.0048 - val_accuracy: 0.6207\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.3048 - accuracy: 0.9062 - val_loss: 0.9218 - val_accuracy: 0.6897\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.3212 - accuracy: 0.8906 - val_loss: 0.8562 - val_accuracy: 0.7586\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2905 - accuracy: 0.9062 - val_loss: 0.9314 - val_accuracy: 0.6724\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2785 - accuracy: 0.8906 - val_loss: 0.9301 - val_accuracy: 0.6207\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2180 - accuracy: 0.9375 - val_loss: 0.8894 - val_accuracy: 0.7414\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.3221 - accuracy: 0.8750 - val_loss: 0.8575 - val_accuracy: 0.7069\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.2201 - accuracy: 0.9531 - val_loss: 0.9663 - val_accuracy: 0.6552\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.3103 - accuracy: 0.8594 - val_loss: 0.8520 - val_accuracy: 0.7586\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2188 - accuracy: 0.9688 - val_loss: 0.9264 - val_accuracy: 0.6552\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2385 - accuracy: 0.9375 - val_loss: 0.9210 - val_accuracy: 0.6379\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2389 - accuracy: 0.9219 - val_loss: 0.8824 - val_accuracy: 0.7414\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2443 - accuracy: 0.8906 - val_loss: 0.8798 - val_accuracy: 0.6724\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2198 - accuracy: 0.9531 - val_loss: 0.9474 - val_accuracy: 0.6379\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.2091 - accuracy: 0.9688 - val_loss: 0.8661 - val_accuracy: 0.7586\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2225 - accuracy: 0.9688 - val_loss: 0.8681 - val_accuracy: 0.7931\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2257 - accuracy: 0.9375 - val_loss: 0.9394 - val_accuracy: 0.6552\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2005 - accuracy: 0.9375 - val_loss: 0.8965 - val_accuracy: 0.6897\n"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "r=model.fit_generator(\n",
    "training_set,\n",
    "validation_data=test_set,\n",
    "epochs=50,\n",
    "steps_per_epoch=len(training_set),\n",
    "validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adequate-gravity",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'legand'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-59cfa79218c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LossVal_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'legand'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the loss\n",
    "plt.plot(r.history['loss'],label='train loss')\n",
    "plt.plot(r.history['val_loss'],label='val loss')\n",
    "plt.legand()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "plt.plot(r.history['accuracy'],label='train acc')\n",
    "plt.plot(r.history['val_accuarcy'],label='val acc')\n",
    "plt.legand()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-property",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
